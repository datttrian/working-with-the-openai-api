{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Working with the OpenAI API\n",
                "\n",
                "## Introduction to the OpenAI API\n",
                "\n",
                "### Your first API request!\n",
                "\n",
                "Throughout the course, you'll write Python code to interact with the\n",
                "OpenAI API. As a first step, you'll need to create your own API key.\n",
                "**API keys used in this course's exercises will not be stored in any\n",
                "way.**\n",
                "\n",
                "To create a key, you'll first need to create an OpenAI account by\n",
                "visiting their [signup page](https://platform.openai.com/signup). Next,\n",
                "navigate to the [API keys\n",
                "page](https://platform.openai.com/account/api-keys) to create your\n",
                "secret key.\n",
                "\n",
                "<img\n",
                "src=\"https://assets.datacamp.com/production/repositories/6309/datasets/842da12a5b68c9f3240978dcfb08726b57ee2a18/api-key-page.png\"\n",
                "style=\"width:100.0%\" alt=\"The button to create a new secret key.\" />\n",
                "\n",
                "OpenAI sometimes provides free credits for the API, but this can differ\n",
                "depending on geography. You may also need to add debit/credit card\n",
                "details. **You'll need less than \\$1 credit to complete this course.**\n",
                "\n",
                "**Warning**: if you send many requests or use lots of tokens in a short\n",
                "period, you may see an `openai.error.RateLimitError`. If you see this\n",
                "error, please wait a minute for your quota to reset and you should be\n",
                "able to begin sending more requests. Please see [OpenAI's rate limit\n",
                "error support\n",
                "article](https://help.openai.com/en/articles/6897202-ratelimiterror) for\n",
                "more information.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Import `OpenAI` from the `openai` library.\n",
                "- Create an API client and assign your API key to the client's `api_key`\n",
                "  argument.\n",
                "- Create a request to the Completions endpoint.\n",
                "- Specify that the request should use the `gpt-3.5-turbo-instruct`\n",
                "  model.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Requirement already satisfied: python-dotenv in /workspaces/working-with-the-openai-api/.venv/lib/python3.12/site-packages (1.0.1)\n",
                        "Requirement already satisfied: openai in /workspaces/working-with-the-openai-api/.venv/lib/python3.12/site-packages (1.23.6)\n",
                        "Requirement already satisfied: anyio<5,>=3.5.0 in /workspaces/working-with-the-openai-api/.venv/lib/python3.12/site-packages (from openai) (4.3.0)\n",
                        "Requirement already satisfied: distro<2,>=1.7.0 in /workspaces/working-with-the-openai-api/.venv/lib/python3.12/site-packages (from openai) (1.9.0)\n",
                        "Requirement already satisfied: httpx<1,>=0.23.0 in /workspaces/working-with-the-openai-api/.venv/lib/python3.12/site-packages (from openai) (0.27.0)\n",
                        "Requirement already satisfied: pydantic<3,>=1.9.0 in /workspaces/working-with-the-openai-api/.venv/lib/python3.12/site-packages (from openai) (2.7.1)\n",
                        "Requirement already satisfied: sniffio in /workspaces/working-with-the-openai-api/.venv/lib/python3.12/site-packages (from openai) (1.3.1)\n",
                        "Requirement already satisfied: tqdm>4 in /workspaces/working-with-the-openai-api/.venv/lib/python3.12/site-packages (from openai) (4.66.2)\n",
                        "Requirement already satisfied: typing-extensions<5,>=4.7 in /workspaces/working-with-the-openai-api/.venv/lib/python3.12/site-packages (from openai) (4.11.0)\n",
                        "Requirement already satisfied: idna>=2.8 in /workspaces/working-with-the-openai-api/.venv/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
                        "Requirement already satisfied: certifi in /workspaces/working-with-the-openai-api/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
                        "Requirement already satisfied: httpcore==1.* in /workspaces/working-with-the-openai-api/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
                        "Requirement already satisfied: h11<0.15,>=0.13 in /workspaces/working-with-the-openai-api/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
                        "Requirement already satisfied: annotated-types>=0.4.0 in /workspaces/working-with-the-openai-api/.venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
                        "Requirement already satisfied: pydantic-core==2.18.2 in /workspaces/working-with-the-openai-api/.venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
                        "Note: you may need to restart the kernel to use updated packages.\n"
                    ]
                }
            ],
            "source": [
                "pip install python-dotenv openai"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "# added/edited\n",
                "from dotenv import load_dotenv\n",
                "import os\n",
                "import openai\n",
                "\n",
                "load_dotenv()\n",
                "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Completion(id='cmpl-9JQ5ddrswfqoT3PjL7rIPAazk53Oe', choices=[CompletionChoice(finish_reason='length', index=0, logprobs=None, text='\\n\\nChatGPT was developed by OpenAI, with contributions from the broader G')], created=1714415549, model='gpt-3.5-turbo-instruct', object='text_completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=16, prompt_tokens=6, total_tokens=22))\n"
                    ]
                }
            ],
            "source": [
                "# Import the OpenAI client\n",
                "from openai import OpenAI\n",
                "\n",
                "# Create the OpenAI client and set your API key\n",
                "client = OpenAI()\n",
                "\n",
                "# Create a request to the Completions endpoint\n",
                "response = client.completions.create(\n",
                "  # Specify the correct model\n",
                "  model=\"gpt-3.5-turbo-instruct\",\n",
                "  prompt=\"Who developed ChatGPT?\"\n",
                ")\n",
                "\n",
                "print(response)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Digging into the response\n",
                "\n",
                "One of the key skills required to work with APIs is manipulating the\n",
                "response to extract the desired information. In this exercise, you'll\n",
                "push your Python dictionary and list manipulation skills to the max to\n",
                "extract information from the API response.\n",
                "\n",
                "You've been provided with `response`, which is a response from the\n",
                "OpenAI API when provided with the prompt, *Who developed ChatGPT?*\n",
                "\n",
                "This `response` object has been printed for you so you can see and\n",
                "understand its structure. If you're struggling to picture the structure,\n",
                "view the dictionary form of the response with `.model_dump()`.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Extract the model used from `response` using attributes.\n",
                "\n",
                "<!-- -->\n",
                "\n",
                "- Extract the total tokens used from `response` using attributes.\n",
                "\n",
                "<!-- -->\n",
                "\n",
                "- Extract the text answer to the prompt from `response`.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "gpt-3.5-turbo-instruct\n",
                        "22\n",
                        "\n",
                        "\n",
                        "ChatGPT was developed by OpenAI, with contributions from the broader G\n"
                    ]
                }
            ],
            "source": [
                "# Extract the model from response\n",
                "print(response.model)\n",
                "\n",
                "# Extract the total_tokens from response\n",
                "print(response.usage.total_tokens)\n",
                "\n",
                "# Extract the text from response\n",
                "print(response.choices[0].text)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## OpenAI's Text and Chat Capabilities\n",
                "\n",
                "### Find and replace\n",
                "\n",
                "Text completion models can be used for much more than answering\n",
                "questions. In this exercise, you'll explore the model's ability to\n",
                "transform a text prompt.\n",
                "\n",
                "Find-and-replace tools have been around for decades, but they are often\n",
                "limited to identifying and replacing exact words or phrases. You've been\n",
                "provided with a block of text discussing cars, and you'll use a\n",
                "completion model to update the text to discuss planes instead, updating\n",
                "the text appropriately.\n",
                "\n",
                "**Warning**: if you send many requests or use lots of tokens in a short\n",
                "period, you may hit your rate limit and see an\n",
                "`openai.error.RateLimitError`. If you see this error, please wait a\n",
                "minute for your quota to reset and you should be able to begin sending\n",
                "more requests. Please see [OpenAI's rate limit error support\n",
                "article](https://help.openai.com/en/articles/6897202-ratelimiterror) for\n",
                "more information.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Assign your API key to `api_key`.\n",
                "- Create a request to the Completions endpoint, sending the `prompt`\n",
                "  provided to the `gpt-3.5-turbo-instruct` model and using\n",
                "  `max_tokens=100`.\n",
                "- Extract and print the text response from the API.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "\n",
                        "A plane is an aircraft that is typically powered by jet engines or propellers. It has wings and is designed to carry passengers and/or cargo through the air. Planes have become a crucial part of modern society, and are used for a variety of purposes, such as commercial travel, military operations, and cargo transportation. Planes are often associated with speed, efficiency, and global connectivity.\n"
                    ]
                }
            ],
            "source": [
                "# Set your API key\n",
                "client = OpenAI()\n",
                "\n",
                "prompt=\"\"\"Replace car with plane and adjust phrase:\n",
                "A car is a vehicle that is typically powered by an internal combustion engine or an electric motor. It has four wheels, and is designed to carry passengers and/or cargo on roads or highways. Cars have become a ubiquitous part of modern society, and are used for a wide variety of purposes, such as commuting, travel, and transportation of goods. Cars are often associated with freedom, independence, and mobility.\"\"\"\n",
                "\n",
                "# Create a request to the Completions endpoint\n",
                "response = client.completions.create(\n",
                "  model=\"gpt-3.5-turbo-instruct\",\n",
                "  prompt=prompt,\n",
                "  max_tokens=100\n",
                ")\n",
                "\n",
                "# Extract and print the response text\n",
                "print(response.choices[0].text)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Text summarization\n",
                "\n",
                "One really common use case for using OpenAI's models is summarizing\n",
                "text. This has a ton of applications in business settings, including\n",
                "summarizing reports into concise one-pagers or a handful of bullet\n",
                "points, or extracting the next steps and timelines for different\n",
                "stakeholders.\n",
                "\n",
                "In this exercise, you'll summarize a passage of text on financial\n",
                "investment into two concise bullet points using a text completion model.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Assign your API key to `api_key`.\n",
                "- Create a request to Completions endpoint, sending the `prompt`\n",
                "  provided; use a maximum of `400` tokens and make the response *more\n",
                "  deterministic*.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "\n",
                        "- Investment involves committing money or capital to an enterprise with the expectation of obtaining added income or profit.\n",
                        "- Careful analysis and diversification can help minimize risk and produce high returns over the long term.\n"
                    ]
                }
            ],
            "source": [
                "# Set your API key\n",
                "client = OpenAI()\n",
                "\n",
                "prompt=\"\"\"Summarize the following text into two concise bullet points:\n",
                "Investment refers to the act of committing money or capital to an enterprise with the expectation of obtaining an added income or profit in return. There are a variety of investment options available, including stocks, bonds, mutual funds, real estate, precious metals, and currencies. Making an investment decision requires careful analysis, assessment of risk, and evaluation of potential rewards. Good investments have the ability to produce high returns over the long term while minimizing risk. Diversification of investment portfolios reduces risk exposure. Investment can be a valuable tool for building wealth, generating income, and achieving financial security. It is important to be diligent and informed when investing to avoid losses.\"\"\"\n",
                "\n",
                "# Create a request to the Completions endpoint\n",
                "response = client.completions.create(\n",
                "  model=\"gpt-3.5-turbo-instruct\",\n",
                "  prompt=prompt,\n",
                "  max_tokens=400,\n",
                "  temperature=0.5\n",
                ")\n",
                "\n",
                "print(response.choices[0].text)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Content generation\n",
                "\n",
                "AI is playing a much greater role in content generation, from creating\n",
                "marketing content such as blog post titles to creating outreach email\n",
                "templates for sales teams.\n",
                "\n",
                "In this exercise, you'll harness AI through the Completions endpoint to\n",
                "generate a catchy slogan for a new restaurant. Feel free to test out\n",
                "different prompts, such as varying the type of cuisine (e.g., Italian,\n",
                "Chinese) or the type of restaurant (e.g., fine-dining, fast-food), to\n",
                "see how the response changes.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Assign your API key to `api_key`.\n",
                "- Create a request to the Completions endpoint to create a slogan for a\n",
                "  new restaurant; set the maximum number of tokens to `100`.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "\n",
                        "\"Satisfy your cravings, spice up your taste buds: Welcome to Flavor Fiesta!\"\n"
                    ]
                }
            ],
            "source": [
                "# Set your API key\n",
                "client = OpenAI()\n",
                "\n",
                "# Create a request to the Completions endpoint\n",
                "response = client.completions.create(\n",
                "  model=\"gpt-3.5-turbo-instruct\",\n",
                "  prompt=\"Create a slogan for a new restaurant.\",\n",
                "  max_tokens=100\n",
                ")\n",
                "\n",
                "print(response.choices[0].text)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Classifying text sentiment\n",
                "\n",
                "As well as answering questions, transforming text, and generating new\n",
                "text, Completions models can also be used for classification tasks, such\n",
                "as categorization and sentiment classification. This sort of task\n",
                "requires not only knowledge of the words but also a deeper understanding\n",
                "of their meaning.\n",
                "\n",
                "In this exercise, you'll explore using Completions models for sentiment\n",
                "classification using reviews from an online shoe store called *Toe-Tally\n",
                "Comfortable*:\n",
                "\n",
                "1.  Unbelievably good!\n",
                "2.  Shoes fell apart on the second use.\n",
                "3.  The shoes look nice, but they aren't very comfortable.\n",
                "4.  Can't wait to show them off!\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Assign your API key to `api_key`.\n",
                "- Create a request to the Completions endpoint to classify the sentiment\n",
                "  of the following statements as either `negative`, `positive`, or\n",
                "  `neutral`:\n",
                "  - Unbelievably good!\n",
                "  - Shoes fell apart on the second use.\n",
                "  - The shoes look nice, but they aren't very comfortable.\n",
                "  - Can't wait to show them off!\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "1. Positive\n",
                        "2. Negative\n",
                        "3. Neutral\n",
                        "4. Positive\n"
                    ]
                }
            ],
            "source": [
                "# Set your API key\n",
                "client = OpenAI()\n",
                "\n",
                "# Create a request to the Completions endpoint\n",
                "response = client.completions.create(\n",
                "  model=\"gpt-3.5-turbo-instruct\",\n",
                "  prompt=\"\"\"Classify sentiment as negative, positive, or neutral:\n",
                "    1. Unbelievably good!\n",
                "    2. Shoes fell apart on the second use.\n",
                "    3. The shoes look nice, but they aren't very comfortable.\n",
                "    4. Can't wait to show them off!\n",
                "  \"\"\",\n",
                "  max_tokens=100\n",
                ")\n",
                "\n",
                "print(response.choices[0].text)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Categorizing companies\n",
                "\n",
                "In this exercise, you'll use a Completions model to categorize different\n",
                "companies. At first, you won't specify the categories to see how the\n",
                "model categorizes them. Then, you'll specify the categories in the\n",
                "prompt to ensure they are categorized in a desirable and predictable\n",
                "way.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Assign your API key to `api_key`.\n",
                "- Create a request to the Completions endpoint to categorize the\n",
                "  following companies: `Apple`, `Microsoft`, `Saudi Aramco`, `Alphabet`,\n",
                "  `Amazon`, `Berkshire Hathaway`, `NVIDIA`, `Meta`, `Tesla`, and `LVMH`;\n",
                "  run the code to see the response.\n",
                "- Alter the prompt to specify the four categories that the companies\n",
                "  should be classified into, `Tech`, `Energy`, `Luxury Goods`, or\n",
                "  `Investment`, and re-run the code.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "\n",
                        "Tech: Apple, Microsoft, Alphabet, Amazon, NVIDIA, Meta\n",
                        "Energy: Saudi Aramco\n",
                        "Luxury Goods: LVMH\n",
                        "Investment: Berkshire Hathaway\n"
                    ]
                }
            ],
            "source": [
                "# Set your API key\n",
                "client = OpenAI()\n",
                "\n",
                "# Create a request to the Completions endpoint\n",
                "response = client.completions.create(\n",
                " model=\"gpt-3.5-turbo-instruct\",\n",
                " prompt=\"Categorize the following list of companies as either Tech, Energy, Luxury Goods, or Investment: Apple, Microsoft, Saudi Aramco, Alphabet, Amazon, Berkshire Hathaway, NVIDIA, Meta, Tesla, LVMH\",\n",
                " max_tokens=100,\n",
                " temperature=0.5\n",
                ")\n",
                "\n",
                "print(response.choices[0].text)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### The Chat Completions endpoint\n",
                "\n",
                "The models available via the Chat Completions endpoint can not only\n",
                "perform similar single-turn tasks as models from the Completions\n",
                "endpoint, but can also be used to have multi-turn conversations.\n",
                "\n",
                "To enable multi-turn conversations, the endpoint supports three\n",
                "different roles:\n",
                "\n",
                "- **System**: controls assistant's *behavior*\n",
                "- **User**: *instruct* the assistant\n",
                "- **Assistant**: response to user instruction\n",
                "\n",
                "In this exercise, you'll make your first request to the Chat Completions\n",
                "endpoint to answer the following question:\n",
                "\n",
                "*What is the difference between a for loop and a while loop?*\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Assign your API key to `api_key`.\n",
                "- Create a request to the Chat Completions endpoint using both *system*\n",
                "  and *user* messages to answer the question, *What is the difference\n",
                "  between a for loop and a while loop?*\n",
                "- Extract and print the assistant's text response.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "A for loop and a while loop are both used for iterating over a block of code multiple times, but they have some key differences:\n",
                        "\n",
                        "1. **For loop:**\n",
                        "   - A for loop is used when you know in advance how many times you want to iterate.\n",
                        "   - The syntax of a for loop typically includes a variable that is used to control the number of iterations and a range or sequence of values.\n",
                        "   - For example, in Python, a for loop can be written like this:\n",
                        "     ```python\n",
                        "     for i in range(5):\n",
                        "         print(i)\n",
                        "     ```\n",
                        "   - In this example, the loop will iterate 5 times, printing the values of `i` from 0 to 4.\n",
                        "\n",
                        "2. **While\n"
                    ]
                }
            ],
            "source": [
                "# Set your API key\n",
                "client = OpenAI()\n",
                "\n",
                "# Create a request to the Chat Completions endpoint\n",
                "response = client.chat.completions.create(\n",
                "  model=\"gpt-3.5-turbo\",\n",
                "  max_tokens=150,\n",
                "  messages=[\n",
                "    {\"role\": \"system\",\n",
                "     \"content\": \"You are a helpful data science tutor.\"},\n",
                "    {\"role\": \"user\",\n",
                "     \"content\": \"What is the difference between a for loop and a while loop?\"}\n",
                "  ]\n",
                ")\n",
                "\n",
                "# Extract the assistant's text response\n",
                "print(response.choices[0].message.content)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Code explanation\n",
                "\n",
                "One of the most popular use cases for using OpenAI models is for\n",
                "explaining complex content, such as technical jargon and code. This is a\n",
                "task that data practitioners, software engineers, and many others must\n",
                "tackle in their day-to-day as they review and utilize code written by\n",
                "others.\n",
                "\n",
                "In this exercise, you'll use the OpenAI API to explain a block of Python\n",
                "code to understand what it is doing.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Assign your API key to `api_key`.\n",
                "- Create a request to the Chat Completions endpoint to send\n",
                "  `instruction` to the `gpt-3.5-turbo` model.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "This code calculates and prints the mean height from the values in the \"heights_dict\" dictionary using the NumPy library.\n"
                    ]
                }
            ],
            "source": [
                "# Set your API key\n",
                "client = OpenAI()\n",
                "\n",
                "instruction = \"\"\"Explain what this Python code does in one sentence:\n",
                "import numpy as np\n",
                "\n",
                "heights_dict = {\"Mark\": 1.76, \"Steve\": 1.88, \"Adnan\": 1.73}\n",
                "heights = heights_dict.values()\n",
                "print(np.mean(heights))\n",
                "\"\"\"\n",
                "\n",
                "# Create a request to the Chat Completions endpoint\n",
                "response = client.chat.completions.create(\n",
                "  model=\"gpt-3.5-turbo\",\n",
                "  messages=[\n",
                "    {\"role\": \"system\", \"content\": \"You are a helpful Python programming assistant.\"},\n",
                "    {\"role\": \"user\", \"content\": instruction}\n",
                "  ],\n",
                "  max_tokens=100\n",
                ")\n",
                "\n",
                "print(response.choices[0].message.content)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### In-context learning\n",
                "\n",
                "For more complex use cases, the models lack the understanding or context\n",
                "of the problem to provide a suitable response from a prompt. In these\n",
                "cases, you need to provide examples to the model for it to learn from,\n",
                "so-called **in-context learning**.\n",
                "\n",
                "In this exercise, you'll improve on a Python programming tutor built on\n",
                "the OpenAI API by providing an example that the model can learn from.\n",
                "\n",
                "Here is an example of a user and assistant message you can use, but feel\n",
                "free to try out your own:\n",
                "\n",
                "- User → *Explain what the min() function does.*\n",
                "- Assistant → *The min() function returns the smallest item from an\n",
                "  iterable.*\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Assign your API key to `api_key`.\n",
                "- Add a similar coding example in the form of user and assistant\n",
                "  messages to `messages` so the model can learn more about the desired\n",
                "  response.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "The type() function returns the type of an object. It can be used to find out the data type of a variable or an expression in Python.\n"
                    ]
                }
            ],
            "source": [
                "# Set your API key\n",
                "client = OpenAI()\n",
                "\n",
                "response = client.chat.completions.create(\n",
                "   model=\"gpt-3.5-turbo\",\n",
                "   # Add a user and assistant message for in-context learning\n",
                "   messages=[\n",
                "     {\"role\": \"system\", \"content\": \"You are a helpful Python programming tutor.\"},\n",
                "     {\"role\": \"user\", \"content\": \"Explain what the min() function does.\"},\n",
                "     {\"role\": \"assistant\", \"content\": \"The min() function returns the smallest item from an iterable.\"},\n",
                "     {\"role\": \"user\", \"content\": \"Explain what the type() function does.\"}\n",
                "   ]\n",
                ")\n",
                "\n",
                "print(response.choices[0].message.content)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Creating an AI chatbot\n",
                "\n",
                "An online learning platform called *Easy as Pi* that specializes in\n",
                "teaching math skills has contracted you to help develop an AI tutor. You\n",
                "immediately see that you can build this feature on top of the OpenAI\n",
                "API, and start to design a simple proof-of-concept (POC) for the major\n",
                "stakeholders at the company. This POC will demonstrate the core\n",
                "functionality required to build the final feature and the power of the\n",
                "OpenAI's GPT models.\n",
                "\n",
                "Example system and user messages have been provided for you, but feel\n",
                "free to play around with these to change the model's behavior or design\n",
                "a completely different chatbot!\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Assign your API key to `api_key`.\n",
                "- Create a dictionary to house the user message in a format that can be\n",
                "  sent to the API; then append it to `messages`.\n",
                "- Create a Chat request to send `messages` to the model.\n",
                "- Extract the assistant's message, convert it to a dictionary, and\n",
                "  append it to `messages`.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "User:  Explain what pi is.\n",
                        "Assistant:  Pi (π) is a mathematical constant representing the ratio of a circle's circumference to its diameter. It is an irrational number, which means it cannot be expressed as a simple fraction and its decimal representation goes on indefinitely without repetition. The value of pi is approximately 3.14159, although it is usually rounded to 3.14 for most calculations. It is an important constant in geometry, trigonometry, and many other branches of mathematics and science. \n",
                        "\n",
                        "User:  Summarize this in two bullet points.\n",
                        "Assistant:  - Pi (π) is the ratio of a circle's circumference to its diameter.\n",
                        "- It is an irrational number with an approximate value of 3.14159, commonly rounded to 3.14. \n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "# Set your API key\n",
                "client = OpenAI()\n",
                "\n",
                "messages = [{\"role\": \"system\", \"content\": \"You are a helpful math tutor.\"}]\n",
                "user_msgs = [\"Explain what pi is.\", \"Summarize this in two bullet points.\"]\n",
                "\n",
                "for q in user_msgs:\n",
                "    print(\"User: \", q)\n",
                "    \n",
                "    # Create a dictionary for the user message from q and append to messages\n",
                "    user_dict = {\"role\": \"user\", \"content\": q}\n",
                "    messages.append(user_dict)\n",
                "    \n",
                "    # Create the API request\n",
                "    response = client.chat.completions.create(\n",
                "        model=\"gpt-3.5-turbo\",\n",
                "        messages=messages,\n",
                "        max_tokens=100\n",
                "    )\n",
                "    \n",
                "    # Convert the assistant's message to a dict and append to messages\n",
                "    assistant_dict = {\"role\": \"assistant\", \"content\": response.choices[0].message.content}\n",
                "    messages.append(assistant_dict)\n",
                "    print(\"Assistant: \", response.choices[0].message.content, \"\\n\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## OpenAI's Text and Chat Capabilities\n",
                "\n",
                "### Requesting moderation\n",
                "\n",
                "Aside from text and chat completion models, OpenAI provides models with\n",
                "other capabilities, including text *moderation*. OpenAI's text\n",
                "moderation model is designed for evaluating prompts and responses to\n",
                "determine if they violate OpenAI's usage policies, including inciting\n",
                "hate speech and promoting violence.\n",
                "\n",
                "In this exercise, you'll test out OpenAI's moderation functionality on a\n",
                "sentence that may have been flagged as containing violent content using\n",
                "traditional word detection algorithms.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Assign your API key to `api_key`.\n",
                "- Create a request to the Moderations endpoint to determine if the text,\n",
                "  `\"My favorite book is How to Kill a Mockingbird.\"` violates OpenAI's\n",
                "  usage policies.\n",
                "- Print the category scores to see the results.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CategoryScores(harassment=1.4550803825841285e-05, harassment_threatening=8.698739293322433e-06, hate=5.186380440136418e-05, hate_threatening=1.6861979190707643e-07, self_harm=1.4029425301487208e-06, self_harm_instructions=6.108327283982362e-07, self_harm_intent=4.3481284706103907e-07, sexual=6.508102160296403e-06, sexual_minors=1.5272981954694842e-06, violence=0.002059031743556261, violence_graphic=4.1700324800331146e-05, self-harm=1.4029425301487208e-06, sexual/minors=1.5272981954694842e-06, hate/threatening=1.6861979190707643e-07, violence/graphic=4.1700324800331146e-05, self-harm/intent=4.3481284706103907e-07, self-harm/instructions=6.108327283982362e-07, harassment/threatening=8.698739293322433e-06)\n"
                    ]
                }
            ],
            "source": [
                "# Set your API key\n",
                "client = OpenAI()\n",
                "\n",
                "# Create a request to the Moderation endpoint\n",
                "response = client.moderations.create(\n",
                "  model=\"text-moderation-latest\",\n",
                "  input=\"My favorite book is How to Kill a Mockingbird.\"\n",
                ")\n",
                "\n",
                "print(response.results[0].category_scores)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Creating a podcast transcript\n",
                "\n",
                "The OpenAI API `Audio` endpoint provides access to the *Whisper* model,\n",
                "which can be used for speech-to-text transcription and translation. In\n",
                "this exercise, you'll create a transcript from a [DataFramed\n",
                "podcast](https://www.datacamp.com/podcast) episode with OpenAI\n",
                "Developer, Logan Kilpatrick.\n",
                "\n",
                "If you'd like to hear more from Logan, check out the full [ChatGPT and\n",
                "the OpenAI Developer\n",
                "Ecosystem](https://www.datacamp.com/podcast/chat-gpt-and-the-open-ai-developer-ecosystem)\n",
                "podcast episode.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Assign your API key to `api_key`.\n",
                "- Open the\n",
                "  [`openai-audio.mp3`](https://assets.datacamp.com/production/repositories/6309/datasets/9e5a65b42c1a9fe8756e30e4d255883a8466b671/audio-logan-advocate-openai.mp3)\n",
                "  file.\n",
                "- Create a transcription request to the Audio endpoint.\n",
                "- Extract and print the transcript text from the `response`.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Hi there, Logan, thank you for joining us on the show today. Thanks for having me. I'm super excited about this. Brilliant. We're going to dive right in, and I think ChatGPT is maybe the most famous AI product that you have at OpenAI, but I'd just like to get an overview of what all the other AIs that are available are. So I think two and a half years ago, OpenAI released the API that we still have available today, which is essentially our giving people access to these models. And for a lot of people, giving people access to the model that powers ChatGPT, which is our consumer-facing first-party application, which essentially just, in very simple terms, puts a nice UI on top of what was already available through our API for the last two and a half years. So it's sort of democratizing the access to this technology through our API. If you want to just play around with it, as an end user, we have ChatGPT available to the world as well.\n"
                    ]
                }
            ],
            "source": [
                "# Set your API key\n",
                "client = OpenAI()\n",
                "\n",
                "# Open the openai-audio.mp3 file\n",
                "audio_file = open(\"openai-audio.mp3\", \"rb\")\n",
                "\n",
                "# Create a transcript from the audio file\n",
                "response = client.audio.transcriptions.create(model=\"whisper-1\", file=audio_file)\n",
                "\n",
                "# Extract and print the transcript text\n",
                "print(response.text)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Transcribing a non-English language\n",
                "\n",
                "The Whisper model can not only transcribe English language, but also\n",
                "performs well on speech in many other languages.\n",
                "\n",
                "In this exercise, you’ll create a transcript from `audio.m4a`, which\n",
                "contains speech in Portuguese.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Assign your API key to `api_key`.\n",
                "- Open the\n",
                "  [`audio.m4a`](https://assets.datacamp.com/production/repositories/6309/datasets/443390237150862833705a6e0599478575a1276a/audio-portuguese.m4a)\n",
                "  file.\n",
                "- Create a request to the Audio endpoint to transcribe `audio.m4a`.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Olá, o meu nome é Eduardo, sou CTO no Datacamp. Espero que esteja a gostar deste curso que o James e eu criamos para você. Esta API permite enviar um áudio e trazer para inglês. O áudio original está em português.\n"
                    ]
                }
            ],
            "source": [
                "# Set your API key\n",
                "client = OpenAI()\n",
                "\n",
                "# Open the audio.m4a file\n",
                "audio_file= open(\"audio.m4a\", \"rb\")\n",
                "\n",
                "# Create a transcript from the audio file\n",
                "response = client.audio.transcriptions.create(model=\"whisper-1\", file=audio_file)\n",
                "\n",
                "print(response.text)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Translating Portuguese\n",
                "\n",
                "Whisper can not only transcribe audio into its native language but also\n",
                "supports translation capabilities for creating English transcriptions.\n",
                "\n",
                "In this exercise, you'll return to the Portuguese audio, but this time,\n",
                "you'll translate it into English!\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Assign your API key to `api_key`.\n",
                "- Open the\n",
                "  [`audio.m4a`](https://assets.datacamp.com/production/repositories/6309/datasets/443390237150862833705a6e0599478575a1276a/audio-portuguese.m4a)\n",
                "  file.\n",
                "- Create a translation request to the Audio endpoint.\n",
                "- Extract and print the translated text from the response.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Hello, my name is Eduardo, I am a CTO at Datacamp. I hope you are enjoying this course that James and I have created for you. This API allows you to send an audio and bring it to English. The original audio is in Portuguese.\n"
                    ]
                }
            ],
            "source": [
                "# Set your API key\n",
                "client = OpenAI()\n",
                "\n",
                "# Open the audio.m4a file\n",
                "audio_file = open(\"audio.m4a\", \"rb\")\n",
                "\n",
                "# Create a translation from the audio file\n",
                "response = client.audio.translations.create(model=\"whisper-1\", file=audio_file)\n",
                "\n",
                "# Extract and print the translated text\n",
                "print(response.text)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Translating with prompts\n",
                "\n",
                "The quality of Whisper's translation can vary depending on the language\n",
                "spoken, the audio quality, and the model's awareness of the subject\n",
                "matter. If you have any extra context about what is being spoken about,\n",
                "you can send it along with the audio to the model to give it a helping\n",
                "hand.\n",
                "\n",
                "You've been provided with with an audio file, `audio.wav`; you're not\n",
                "sure what language is spoken in it, but you do know it relates to a\n",
                "recent World Bank report. Because you don't know how well the model will\n",
                "perform on this unknown language, you opt to send the model this extra\n",
                "context to steer it in the right direction.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Assign your API key to `api_key`.\n",
                "- Open the\n",
                "  [`audio.wav`](https://assets.datacamp.com/production/repositories/6309/datasets/c04d4830a7498cba96639e780cc7ef240b0d3033/mandarin-full.wav)\n",
                "  file.\n",
                "- Write a prompt that informs the model that the audio relates to a\n",
                "  recent World Bank report, which will help the model produce an\n",
                "  accurate translation.\n",
                "- Create a request to the Audio endpoint to transcribe `audio.wav` using\n",
                "  your `prompt`.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "The World Bank said in its latest economic outlook report that the global economy is in a dangerous state. As interest rates rise, consumer spending and corporate investment will slow down, economic activities will be impacted, and the vulnerability of low-income countries will be exposed. Global economic growth will be significantly slowed down, and the stability of the financial system will be threatened.\n"
                    ]
                }
            ],
            "source": [
                "# Set your API key\n",
                "client = OpenAI()\n",
                "\n",
                "# Open the audio.wav file\n",
                "audio_file = open(\"audio.wav\", \"rb\")\n",
                "\n",
                "# Write an appropriate prompt to help the model\n",
                "prompt = \"The transcript contains a discussion on a recent World Bank Report.\"\n",
                "\n",
                "# Create a translation from the audio file\n",
                "response = client.audio.translations.create(model=\"whisper-1\",\n",
                "                                            file=audio_file,\n",
                "                                            prompt=prompt)\n",
                "\n",
                "print(response.text)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Identifying audio language\n",
                "\n",
                "You've learned that you're not only limited to creating a single\n",
                "request, and that you can actually feed the output of one model as an\n",
                "input to another! This is called **chaining**, and it opens to the doors\n",
                "to more complex, multi-modal use cases.\n",
                "\n",
                "In this exercise, you'll practice model chaining to identify the\n",
                "language used in an audio file. You'll do this by bringing together\n",
                "OpenAI's audio transcription functionality and its text models with only\n",
                "a few lines of code.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Assign your API key to `api_key`.\n",
                "- Open the\n",
                "  [`audio.wav`](https://assets.datacamp.com/production/repositories/6309/datasets/f214c0ab90fb25d9f532a9327f15c4112d8c03f5/arne-german-automotive-forecast.wav)\n",
                "  file and assign to `audio_file`.\n",
                "- Create a transcript from `audio_file` and assign to `transcript`.\n",
                "- Prompt a text model using the text from `transcript` to discover the\n",
                "  language used in `audio.wav`; print the model's response.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Set your API key\n",
                "client = OpenAI()\n",
                "\n",
                "# Open the audio.wav file\n",
                "audio_file = open(\"audio.wav\", \"rb\")\n",
                "\n",
                "# Create a transcription request using audio_file\n",
                "audio_response = client.audio.transcriptions.create(model=\"whisper-1\", file=audio_file)\n",
                "\n",
                "# Create a request to the API to identify the language spoken\n",
                "chat_response = client.chat.completions.create(\n",
                "  model=\"gpt-3.5-turbo\",\n",
                "  messages=[\n",
                "    {\"role\": \"system\", \"content\": \"You are a languages specialist.\"},\n",
                "    {\"role\": \"user\", \"content\": \"Identify the language used in the following text: \" + audio_response.text}\n",
                "  ]\n",
                ")\n",
                "print(chat_response.choices[0].message.content)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Creating meeting summaries\n",
                "\n",
                "Time for business! One time-consuming task that many find themselves\n",
                "doing day-to-day is taking meeting notes to summarize attendees,\n",
                "discussion points, next steps, etc.\n",
                "\n",
                "In this exercise, you'll use AI to augment this task to not only save a\n",
                "substantial amount of time, but also to empower attendees to focus on\n",
                "the discussion rather than administrative tasks. You've been provided\n",
                "with a recording from [DataCamp's Q2\n",
                "Roadmap](https://www.datacamp.com/resources/webinars/datacamp-q2-2023-roadmap)\n",
                "webinar, which summarizes what DataCamp will be releasing during that\n",
                "quarter. You'll chain the Whisper model with a text or chat model to\n",
                "discover which courses will be launched in Q2.\n",
                "\n",
                "**Instructions**\n",
                "\n",
                "- Assign your API key to `api_key`.\n",
                "- Open the\n",
                "  [`datacamp-q2-roadmap.mp3`](https://assets.datacamp.com/production/repositories/6309/datasets/9f56370cdaaa3e8090d5e30a7438f5ab3cdedd10/datacamp-q2-roadmap-short.mp3)\n",
                "  file and assign to `audio_file`.\n",
                "- Create a transcript from `audio_file` and assign to `transcript`.\n",
                "- Prompt a text model using the text from `transcript` and summarize it\n",
                "  into concise bullet points.\n",
                "\n",
                "**Answer**\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Set your API key\n",
                "client = OpenAI()\n",
                "\n",
                "# Open the datacamp-q2-roadmap.mp3 file\n",
                "audio_file = open(\"datacamp-q2-roadmap.mp3\", \"rb\")\n",
                "\n",
                "# Create a transcription request using audio_file\n",
                "audio_response = client.audio.transcriptions.create(model=\"whisper-1\", file=audio_file)\n",
                "\n",
                "# Create a request to the API to summarize the transcript into bullet points\n",
                "chat_response = client.chat.completions.create(\n",
                "  model=\"gpt-3.5-turbo\",\n",
                "  messages=[\n",
                "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
                "    {\"role\": \"user\", \"content\": \"List the courses that DataCamp will be making as bullet points.\" + audio_response.text}\n",
                "  ],\n",
                "  max_tokens=100\n",
                ")\n",
                "print(chat_response.choices[0].message.content)\n"
            ]
        }
    ],
    "metadata": {
        "anaconda-cloud": "",
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.2"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}
