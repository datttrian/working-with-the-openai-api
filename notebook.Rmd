# Working with the OpenAI API

## Introduction to the OpenAI API

### Your first API request!

Throughout the course, you'll write Python code to interact with the
OpenAI API. As a first step, you'll need to create your own API key.
**API keys used in this course's exercises will not be stored in any
way.**

To create a key, you'll first need to create an OpenAI account by
visiting their [signup page](https://platform.openai.com/signup). Next,
navigate to the [API keys
page](https://platform.openai.com/account/api-keys) to create your
secret key.

<img
src="https://assets.datacamp.com/production/repositories/6309/datasets/842da12a5b68c9f3240978dcfb08726b57ee2a18/api-key-page.png"
style="width:100.0%" alt="The button to create a new secret key." />

OpenAI sometimes provides free credits for the API, but this can differ
depending on geography. You may also need to add debit/credit card
details. **You'll need less than \$1 credit to complete this course.**

**Warning**: if you send many requests or use lots of tokens in a short
period, you may see an `openai.error.RateLimitError`. If you see this
error, please wait a minute for your quota to reset and you should be
able to begin sending more requests. Please see [OpenAI's rate limit
error support
article](https://help.openai.com/en/articles/6897202-ratelimiterror) for
more information.

**Instructions**

- Import `OpenAI` from the `openai` library.
- Create an API client and assign your API key to the client's `api_key`
  argument.
- Create a request to the Completions endpoint.
- Specify that the request should use the `gpt-3.5-turbo-instruct`
  model.

**Answer**

```{python}
# Import the OpenAI client
from openai import OpenAI

# Create the OpenAI client and set your API key
client = OpenAI()

# Create a request to the Completions endpoint
response = client.completions.create(
  # Specify the correct model
  model="gpt-3.5-turbo-instruct",
  prompt="Who developed ChatGPT?"
)

print(response)
```

### Digging into the response

One of the key skills required to work with APIs is manipulating the
response to extract the desired information. In this exercise, you'll
push your Python dictionary and list manipulation skills to the max to
extract information from the API response.

You've been provided with `response`, which is a response from the
OpenAI API when provided with the prompt, *Who developed ChatGPT?*

This `response` object has been printed for you so you can see and
understand its structure. If you're struggling to picture the structure,
view the dictionary form of the response with `.model_dump()`.

**Instructions**

- Extract the model used from `response` using attributes.

<!-- -->

- Extract the total tokens used from `response` using attributes.

<!-- -->

- Extract the text answer to the prompt from `response`.

**Answer**

```{python}
# Extract the model from response
print(response.model)

# Extract the total_tokens from response
print(response.usage.total_tokens)

# Extract the text from response
print(response.choices[0].text)
```

## OpenAI's Text and Chat Capabilities

### Find and replace

Text completion models can be used for much more than answering
questions. In this exercise, you'll explore the model's ability to
transform a text prompt.

Find-and-replace tools have been around for decades, but they are often
limited to identifying and replacing exact words or phrases. You've been
provided with a block of text discussing cars, and you'll use a
completion model to update the text to discuss planes instead, updating
the text appropriately.

**Warning**: if you send many requests or use lots of tokens in a short
period, you may hit your rate limit and see an
`openai.error.RateLimitError`. If you see this error, please wait a
minute for your quota to reset and you should be able to begin sending
more requests. Please see [OpenAI's rate limit error support
article](https://help.openai.com/en/articles/6897202-ratelimiterror) for
more information.

**Instructions**

- Assign your API key to `api_key`.
- Create a request to the Completions endpoint, sending the `prompt`
  provided to the `gpt-3.5-turbo-instruct` model and using
  `max_tokens=100`.
- Extract and print the text response from the API.

**Answer**

```{python}
# Set your API key
client = OpenAI()

prompt="""Replace car with plane and adjust phrase:
A car is a vehicle that is typically powered by an internal combustion engine or an electric motor. It has four wheels, and is designed to carry passengers and/or cargo on roads or highways. Cars have become a ubiquitous part of modern society, and are used for a wide variety of purposes, such as commuting, travel, and transportation of goods. Cars are often associated with freedom, independence, and mobility."""

# Create a request to the Completions endpoint
response = client.completions.create(
  model="gpt-3.5-turbo-instruct",
  prompt=prompt,
  max_tokens=100
)

# Extract and print the response text
print(response.choices[0].text)
```

### Text summarization

One really common use case for using OpenAI's models is summarizing
text. This has a ton of applications in business settings, including
summarizing reports into concise one-pagers or a handful of bullet
points, or extracting the next steps and timelines for different
stakeholders.

In this exercise, you'll summarize a passage of text on financial
investment into two concise bullet points using a text completion model.

**Instructions**

- Assign your API key to `api_key`.
- Create a request to Completions endpoint, sending the `prompt`
  provided; use a maximum of `400` tokens and make the response *more
  deterministic*.

**Answer**

```{python}
# Set your API key
client = OpenAI()

prompt="""Summarize the following text into two concise bullet points:
Investment refers to the act of committing money or capital to an enterprise with the expectation of obtaining an added income or profit in return. There are a variety of investment options available, including stocks, bonds, mutual funds, real estate, precious metals, and currencies. Making an investment decision requires careful analysis, assessment of risk, and evaluation of potential rewards. Good investments have the ability to produce high returns over the long term while minimizing risk. Diversification of investment portfolios reduces risk exposure. Investment can be a valuable tool for building wealth, generating income, and achieving financial security. It is important to be diligent and informed when investing to avoid losses."""

# Create a request to the Completions endpoint
response = client.completions.create(
  model="gpt-3.5-turbo-instruct",
  prompt=prompt,
  max_tokens=400,
  temperature=0.5
)

print(response.choices[0].text)
```

### Content generation

AI is playing a much greater role in content generation, from creating
marketing content such as blog post titles to creating outreach email
templates for sales teams.

In this exercise, you'll harness AI through the Completions endpoint to
generate a catchy slogan for a new restaurant. Feel free to test out
different prompts, such as varying the type of cuisine (e.g., Italian,
Chinese) or the type of restaurant (e.g., fine-dining, fast-food), to
see how the response changes.

**Instructions**

- Assign your API key to `api_key`.
- Create a request to the Completions endpoint to create a slogan for a
  new restaurant; set the maximum number of tokens to `100`.

**Answer**

```{python}
# Set your API key
client = OpenAI()

# Create a request to the Completions endpoint
response = client.completions.create(
  model="gpt-3.5-turbo-instruct",
  prompt="Create a slogan for a new restaurant.",
  max_tokens=100
)

print(response.choices[0].text)
```

### Classifying text sentiment

As well as answering questions, transforming text, and generating new
text, Completions models can also be used for classification tasks, such
as categorization and sentiment classification. This sort of task
requires not only knowledge of the words but also a deeper understanding
of their meaning.

In this exercise, you'll explore using Completions models for sentiment
classification using reviews from an online shoe store called *Toe-Tally
Comfortable*:

1.  Unbelievably good!
2.  Shoes fell apart on the second use.
3.  The shoes look nice, but they aren't very comfortable.
4.  Can't wait to show them off!

**Instructions**

- Assign your API key to `api_key`.
- Create a request to the Completions endpoint to classify the sentiment
  of the following statements as either `negative`, `positive`, or
  `neutral`:
  - Unbelievably good!
  - Shoes fell apart on the second use.
  - The shoes look nice, but they aren't very comfortable.
  - Can't wait to show them off!

**Answer**

```{python}
# Set your API key
client = OpenAI()

# Create a request to the Completions endpoint
response = client.completions.create(
  model="gpt-3.5-turbo-instruct",
  prompt="""Classify sentiment as negative, positive, or neutral:
    1. Unbelievably good!
    2. Shoes fell apart on the second use.
    3. The shoes look nice, but they aren't very comfortable.
    4. Can't wait to show them off!
  """,
  max_tokens=100
)

print(response.choices[0].text)
```

### Categorizing companies

In this exercise, you'll use a Completions model to categorize different
companies. At first, you won't specify the categories to see how the
model categorizes them. Then, you'll specify the categories in the
prompt to ensure they are categorized in a desirable and predictable
way.

**Instructions**

- Assign your API key to `api_key`.
- Create a request to the Completions endpoint to categorize the
  following companies: `Apple`, `Microsoft`, `Saudi Aramco`, `Alphabet`,
  `Amazon`, `Berkshire Hathaway`, `NVIDIA`, `Meta`, `Tesla`, and `LVMH`;
  run the code to see the response.
- Alter the prompt to specify the four categories that the companies
  should be classified into, `Tech`, `Energy`, `Luxury Goods`, or
  `Investment`, and re-run the code.

**Answer**

```{python}
# Set your API key
client = OpenAI()

# Create a request to the Completions endpoint
response = client.completions.create(
 model="gpt-3.5-turbo-instruct",
 prompt="Categorize the following list of companies as either Tech, Energy, Luxury Goods, or Investment: Apple, Microsoft, Saudi Aramco, Alphabet, Amazon, Berkshire Hathaway, NVIDIA, Meta, Tesla, LVMH",
 max_tokens=100,
 temperature=0.5
)

print(response.choices[0].text)
```

### The Chat Completions endpoint

The models available via the Chat Completions endpoint can not only
perform similar single-turn tasks as models from the Completions
endpoint, but can also be used to have multi-turn conversations.

To enable multi-turn conversations, the endpoint supports three
different roles:

- **System**: controls assistant's *behavior*
- **User**: *instruct* the assistant
- **Assistant**: response to user instruction

In this exercise, you'll make your first request to the Chat Completions
endpoint to answer the following question:

*What is the difference between a for loop and a while loop?*

**Instructions**

- Assign your API key to `api_key`.
- Create a request to the Chat Completions endpoint using both *system*
  and *user* messages to answer the question, *What is the difference
  between a for loop and a while loop?*
- Extract and print the assistant's text response.

**Answer**

```{python}
# Set your API key
client = OpenAI()

# Create a request to the Chat Completions endpoint
response = client.chat.completions.create(
  model="gpt-3.5-turbo",
  max_tokens=150,
  messages=[
    {"role": "system",
     "content": "You are a helpful data science tutor."},
    {"role": "user",
     "content": "What is the difference between a for loop and a while loop?"}
  ]
)

# Extract the assistant's text response
print(response.choices[0].message.content)
```

### Code explanation

One of the most popular use cases for using OpenAI models is for
explaining complex content, such as technical jargon and code. This is a
task that data practitioners, software engineers, and many others must
tackle in their day-to-day as they review and utilize code written by
others.

In this exercise, you'll use the OpenAI API to explain a block of Python
code to understand what it is doing.

**Instructions**

- Assign your API key to `api_key`.
- Create a request to the Chat Completions endpoint to send
  `instruction` to the `gpt-3.5-turbo` model.

**Answer**

```{python}
# Set your API key
client = OpenAI()

instruction = """Explain what this Python code does in one sentence:
import numpy as np

heights_dict = {"Mark": 1.76, "Steve": 1.88, "Adnan": 1.73}
heights = heights_dict.values()
print(np.mean(heights))
"""

# Create a request to the Chat Completions endpoint
response = client.chat.completions.create(
  model="gpt-3.5-turbo",
  messages=[
    {"role": "system", "content": "You are a helpful Python programming assistant."},
    {"role": "user", "content": instruction}
  ],
  max_tokens=100
)

print(response.choices[0].message.content)
```

### In-context learning

For more complex use cases, the models lack the understanding or context
of the problem to provide a suitable response from a prompt. In these
cases, you need to provide examples to the model for it to learn from,
so-called **in-context learning**.

In this exercise, you'll improve on a Python programming tutor built on
the OpenAI API by providing an example that the model can learn from.

Here is an example of a user and assistant message you can use, but feel
free to try out your own:

- User → *Explain what the min() function does.*
- Assistant → *The min() function returns the smallest item from an
  iterable.*

**Instructions**

- Assign your API key to `api_key`.
- Add a similar coding example in the form of user and assistant
  messages to `messages` so the model can learn more about the desired
  response.

**Answer**

```{python}
# Set your API key
client = OpenAI()

response = client.chat.completions.create(
   model="gpt-3.5-turbo",
   # Add a user and assistant message for in-context learning
   messages=[
     {"role": "system", "content": "You are a helpful Python programming tutor."},
     {"role": "user", "content": "Explain what the min() function does."},
     {"role": "assistant", "content": "The min() function returns the smallest item from an iterable."},
     {"role": "user", "content": "Explain what the type() function does."}
   ]
)

print(response.choices[0].message.content)
```

### Creating an AI chatbot

An online learning platform called *Easy as Pi* that specializes in
teaching math skills has contracted you to help develop an AI tutor. You
immediately see that you can build this feature on top of the OpenAI
API, and start to design a simple proof-of-concept (POC) for the major
stakeholders at the company. This POC will demonstrate the core
functionality required to build the final feature and the power of the
OpenAI's GPT models.

Example system and user messages have been provided for you, but feel
free to play around with these to change the model's behavior or design
a completely different chatbot!

**Instructions**

- Assign your API key to `api_key`.
- Create a dictionary to house the user message in a format that can be
  sent to the API; then append it to `messages`.
- Create a Chat request to send `messages` to the model.
- Extract the assistant's message, convert it to a dictionary, and
  append it to `messages`.

**Answer**

```{python}
# Set your API key
client = OpenAI()

messages = [{"role": "system", "content": "You are a helpful math tutor."}]
user_msgs = ["Explain what pi is.", "Summarize this in two bullet points."]

for q in user_msgs:
    print("User: ", q)
    
    # Create a dictionary for the user message from q and append to messages
    user_dict = {"role": "user", "content": q}
    messages.append(user_dict)
    
    # Create the API request
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=messages,
        max_tokens=100
    )
    
    # Convert the assistant's message to a dict and append to messages
    assistant_dict = {"role": "assistant", "content": response.choices[0].message.content}
    messages.append(assistant_dict)
    print("Assistant: ", response.choices[0].message.content, "\n")
```

## OpenAI's Text and Chat Capabilities

### Requesting moderation

Aside from text and chat completion models, OpenAI provides models with
other capabilities, including text *moderation*. OpenAI's text
moderation model is designed for evaluating prompts and responses to
determine if they violate OpenAI's usage policies, including inciting
hate speech and promoting violence.

In this exercise, you'll test out OpenAI's moderation functionality on a
sentence that may have been flagged as containing violent content using
traditional word detection algorithms.

**Instructions**

- Assign your API key to `api_key`.
- Create a request to the Moderations endpoint to determine if the text,
  `"My favorite book is How to Kill a Mockingbird."` violates OpenAI's
  usage policies.
- Print the category scores to see the results.

**Answer**

```{python}
# Set your API key
client = OpenAI()

# Create a request to the Moderation endpoint
response = client.moderations.create(
  model="text-moderation-latest",
  input="My favorite book is How to Kill a Mockingbird."
)

print(response.results[0].category_scores)
```

### Creating a podcast transcript

The OpenAI API `Audio` endpoint provides access to the *Whisper* model,
which can be used for speech-to-text transcription and translation. In
this exercise, you'll create a transcript from a [DataFramed
podcast](https://www.datacamp.com/podcast) episode with OpenAI
Developer, Logan Kilpatrick.

If you'd like to hear more from Logan, check out the full [ChatGPT and
the OpenAI Developer
Ecosystem](https://www.datacamp.com/podcast/chat-gpt-and-the-open-ai-developer-ecosystem)
podcast episode.

**Instructions**

- Assign your API key to `api_key`.
- Open the
  [`openai-audio.mp3`](https://assets.datacamp.com/production/repositories/6309/datasets/9e5a65b42c1a9fe8756e30e4d255883a8466b671/audio-logan-advocate-openai.mp3)
  file.
- Create a transcription request to the Audio endpoint.
- Extract and print the transcript text from the `response`.

**Answer**

```{python}
# Set your API key
client = OpenAI()

# Open the openai-audio.mp3 file
audio_file = open("openai-audio.mp3", "rb")

# Create a transcript from the audio file
response = client.audio.transcriptions.create(model="whisper-1", file=audio_file)

# Extract and print the transcript text
print(response.text)
```

### Transcribing a non-English language

The Whisper model can not only transcribe English language, but also
performs well on speech in many other languages.

In this exercise, you’ll create a transcript from `audio.m4a`, which
contains speech in Portuguese.

**Instructions**

- Assign your API key to `api_key`.
- Open the
  [`audio.m4a`](https://assets.datacamp.com/production/repositories/6309/datasets/443390237150862833705a6e0599478575a1276a/audio-portuguese.m4a)
  file.
- Create a request to the Audio endpoint to transcribe `audio.m4a`.

**Answer**

```{python}
# Set your API key
client = OpenAI()

# Open the audio.m4a file
audio_file= open("audio.m4a", "rb")

# Create a transcript from the audio file
response = client.audio.transcriptions.create(model="whisper-1", file=audio_file)

print(response.text)
```

### Translating Portuguese

Whisper can not only transcribe audio into its native language but also
supports translation capabilities for creating English transcriptions.

In this exercise, you'll return to the Portuguese audio, but this time,
you'll translate it into English!

**Instructions**

- Assign your API key to `api_key`.
- Open the
  [`audio.m4a`](https://assets.datacamp.com/production/repositories/6309/datasets/443390237150862833705a6e0599478575a1276a/audio-portuguese.m4a)
  file.
- Create a translation request to the Audio endpoint.
- Extract and print the translated text from the response.

**Answer**

```{python}
# Set your API key
client = OpenAI()

# Open the audio.m4a file
audio_file = open("audio.m4a", "rb")

# Create a translation from the audio file
response = client.audio.translations.create(model="whisper-1", file=audio_file)

# Extract and print the translated text
print(response.text)
```

### Translating with prompts

The quality of Whisper's translation can vary depending on the language
spoken, the audio quality, and the model's awareness of the subject
matter. If you have any extra context about what is being spoken about,
you can send it along with the audio to the model to give it a helping
hand.

You've been provided with with an audio file, `audio.wav`; you're not
sure what language is spoken in it, but you do know it relates to a
recent World Bank report. Because you don't know how well the model will
perform on this unknown language, you opt to send the model this extra
context to steer it in the right direction.

**Instructions**

- Assign your API key to `api_key`.
- Open the
  [`audio.wav`](https://assets.datacamp.com/production/repositories/6309/datasets/c04d4830a7498cba96639e780cc7ef240b0d3033/mandarin-full.wav)
  file.
- Write a prompt that informs the model that the audio relates to a
  recent World Bank report, which will help the model produce an
  accurate translation.
- Create a request to the Audio endpoint to transcribe `audio.wav` using
  your `prompt`.

**Answer**

```{python}
# Set your API key
client = OpenAI()

# Open the audio.wav file
audio_file = open("audio.wav", "rb")

# Write an appropriate prompt to help the model
prompt = "The transcript contains a discussion on a recent World Bank Report."

# Create a translation from the audio file
response = client.audio.translations.create(model="whisper-1",
                                            file=audio_file,
                                            prompt=prompt)

print(response.text)
```

### Identifying audio language

You've learned that you're not only limited to creating a single
request, and that you can actually feed the output of one model as an
input to another! This is called **chaining**, and it opens to the doors
to more complex, multi-modal use cases.

In this exercise, you'll practice model chaining to identify the
language used in an audio file. You'll do this by bringing together
OpenAI's audio transcription functionality and its text models with only
a few lines of code.

**Instructions**

- Assign your API key to `api_key`.
- Open the
  [`audio.wav`](https://assets.datacamp.com/production/repositories/6309/datasets/f214c0ab90fb25d9f532a9327f15c4112d8c03f5/arne-german-automotive-forecast.wav)
  file and assign to `audio_file`.
- Create a transcript from `audio_file` and assign to `transcript`.
- Prompt a text model using the text from `transcript` to discover the
  language used in `audio.wav`; print the model's response.

**Answer**

```{python}
# Set your API key
client = OpenAI()

# Open the audio.wav file
audio_file = open("audio.wav", "rb")

# Create a transcription request using audio_file
audio_response = client.audio.transcriptions.create(model="whisper-1", file=audio_file)

# Create a request to the API to identify the language spoken
chat_response = client.chat.completions.create(
  model="gpt-3.5-turbo",
  messages=[
    {"role": "system", "content": "You are a languages specialist."},
    {"role": "user", "content": "Identify the language used in the following text: " + audio_response.text}
  ]
)
print(chat_response.choices[0].message.content)
```

### Creating meeting summaries

Time for business! One time-consuming task that many find themselves
doing day-to-day is taking meeting notes to summarize attendees,
discussion points, next steps, etc.

In this exercise, you'll use AI to augment this task to not only save a
substantial amount of time, but also to empower attendees to focus on
the discussion rather than administrative tasks. You've been provided
with a recording from [DataCamp's Q2
Roadmap](https://www.datacamp.com/resources/webinars/datacamp-q2-2023-roadmap)
webinar, which summarizes what DataCamp will be releasing during that
quarter. You'll chain the Whisper model with a text or chat model to
discover which courses will be launched in Q2.

**Instructions**

- Assign your API key to `api_key`.
- Open the
  [`datacamp-q2-roadmap.mp3`](https://assets.datacamp.com/production/repositories/6309/datasets/9f56370cdaaa3e8090d5e30a7438f5ab3cdedd10/datacamp-q2-roadmap-short.mp3)
  file and assign to `audio_file`.
- Create a transcript from `audio_file` and assign to `transcript`.
- Prompt a text model using the text from `transcript` and summarize it
  into concise bullet points.

**Answer**

```{python}
# Set your API key
client = OpenAI()

# Open the datacamp-q2-roadmap.mp3 file
audio_file = open("datacamp-q2-roadmap.mp3", "rb")

# Create a transcription request using audio_file
audio_response = client.audio.transcriptions.create(model="whisper-1", file=audio_file)

# Create a request to the API to summarize the transcript into bullet points
chat_response = client.chat.completions.create(
  model="gpt-3.5-turbo",
  messages=[
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "List the courses that DataCamp will be making as bullet points." + audio_response.text}
  ],
  max_tokens=100
)
print(chat_response.choices[0].message.content)
```
